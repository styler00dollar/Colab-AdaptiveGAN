{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-AdaptiveGAN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0XMpMJA_g6G",
        "colab_type": "text"
      },
      "source": [
        "# Colab-AdaptiveGAN\n",
        "\n",
        "Original repo: [GuardSkill/AdaptiveGAN](https://github.com/GuardSkill/AdaptiveGAN)\n",
        "\n",
        "Differentiable Augmentation: [mit-han-lab/data-efficient-gans](https://github.com/mit-han-lab/data-efficient-gans)\n",
        "\n",
        "My fork: [styler00dollar/Colab-AdaptiveGAN](https://github.com/styler00dollar/Colab-AdaptiveGAN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2rX88ZABawN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mI4uWGr7_gXo",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title git clone and install\n",
        "!git clone https://github.com/GuardSkill/AdaptiveGAN\n",
        "%cd AdaptiveGAN\n",
        "!pip3 install -r requirements.txt\n",
        "!mkdir /content/model-checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRDsgJNXA2zN",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title config.yml\n",
        "%%writefile /content/checkpoints/config.yml\n",
        "MODE: 1             # 1: train, 2: test, 3: eval\n",
        "MASK: 3             # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)  6: one to one image mask\n",
        "SEED: 10            # random seed\n",
        "GPU: [0]            # list of gpu ids\n",
        "DEBUG: 0           # turns on debugging mode\n",
        "VERBOSE: 0          # turns on verbose mode in the output console\n",
        "\n",
        "TRAIN_FLIST: \"/content/train/train.tflist\"\n",
        "VAL_FLIST: \"/content/val/val.tflist\"\n",
        "TEST_FLIST: \"/content/val/val.tflist\"\n",
        "\n",
        "TRAIN_MASK_FLIST: \"/content/mask_train/mask_train.tflist\"\n",
        "VAL_MASK_FLIST: \"/content/mask_val/mask_val.tflist\"\n",
        "TEST_MASK_FLIST: \"/content/mask_val/mask_val.tflist\"\n",
        "\n",
        "BLOCKS: 4                     # set the res block in each stage\n",
        "LR: 1e-4                      # learning rate\n",
        "D2G_LR: 0.1                   # discriminator/generator learning rate ratio\n",
        "BETA1: 0.0                    # adam optimizer beta1\n",
        "BETA2: 0.9                    # adam optimizer beta2\n",
        "BATCH_SIZE: 1                 # input batch size for training #6\n",
        "INPUT_SIZE: 256               # input image size for training 0 for original size\n",
        "MAX_ITERS: 2e6                # maximum number of iterations to train the model\n",
        "MAX_STEPS: 5000               # maximum number of each epoch\n",
        "MAX_EPOCHES: 100              # maximum number of epoches\n",
        "LOADWITHEPOCH: 1              # if load epoch when loading model \n",
        "\n",
        "L1_LOSS_WEIGHT: 1             # l1 loss weight\n",
        "FM_LOSS_WEIGHT: 10            # feature-matching loss weight\n",
        "STYLE_LOSS_WEIGHT: 250        # style loss weight\n",
        "CONTENT_LOSS_WEIGHT: 0.1      # perceptual loss weight\n",
        "INPAINT_ADV_LOSS_WEIGHT: 0.1  # adversarial loss weight\n",
        "\n",
        "GAN_LOSS: nsgan               # nsgan | lsgan | hinge\n",
        "GAN_POOL_SIZE: 0              # fake images pool size\n",
        "\n",
        "SAVE_INTERVAL: 1000           # how many iterations to wait before saving model (0: never)\n",
        "SAMPLE_INTERVAL: 1000         # how many iterations to wait before sampling (0: never)\n",
        "SAMPLE_SIZE: 1               # number of images to sample #12\n",
        "EVAL_INTERVAL: 20             # How many INTERVAL sample while valuation  (0: never  36000 in places)\n",
        "LOG_INTERVAL: 10              # how many iterations to wait before logging training status (0: never)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQxoE-FTcvuJ",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh1lLMVac0me",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Differentiable Augmentation (experimental)\n",
        "%%writefile /content/AdaptiveGAN/src/models.py\n",
        "\n",
        "# Differentiable Augmentation for Data-Efficient GAN Training\n",
        "# Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, and Song Han\n",
        "# https://arxiv.org/pdf/2006.10738\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def DiffAugment(x, policy='', channels_first=True):\n",
        "    if policy:\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 3, 1, 2)\n",
        "        for p in policy.split(','):\n",
        "            for f in AUGMENT_FNS[p]:\n",
        "                x = f(x)\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 2, 3, 1)\n",
        "        x = x.contiguous()\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_brightness(x):\n",
        "    x = x + (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) - 0.5)\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_saturation(x):\n",
        "    x_mean = x.mean(dim=1, keepdim=True)\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) * 2) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_contrast(x):\n",
        "    x_mean = x.mean(dim=[1, 2, 3], keepdim=True)\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) + 0.5) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_translation(x, ratio=0.125):\n",
        "    shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n",
        "    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
        "    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])\n",
        "    x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2)\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_cutout(x, ratio=0.5):\n",
        "    cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    offset_x = torch.randint(0, x.size(2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    offset_y = torch.randint(0, x.size(3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=x.size(2) - 1)\n",
        "    grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=x.size(3) - 1)\n",
        "    mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
        "    mask[grid_batch, grid_x, grid_y] = 0\n",
        "    x = x * mask.unsqueeze(1)\n",
        "    return x\n",
        "\n",
        "\n",
        "AUGMENT_FNS = {\n",
        "    'color': [rand_brightness, rand_saturation, rand_contrast],\n",
        "    'translation': [rand_translation],\n",
        "    'cutout': [rand_cutout],\n",
        "}\n",
        "\n",
        "policy = 'color,translation,cutout'\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from .networks import Discriminator\n",
        "from .blocks import LinkNet, PyramidNet\n",
        "\n",
        "from .loss import AdversarialLoss, PerceptualLoss, StyleLoss, GradientLoss\n",
        "\n",
        "\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, name, config):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "        self.name = name\n",
        "        self.config = config\n",
        "        self.iteration = 0\n",
        "        self.epoch = None\n",
        "        self.gen_weights_path = os.path.join(config.PATH, name + '_gen.pth')\n",
        "        self.dis_weights_path = os.path.join(config.PATH, name + '_dis.pth')\n",
        "\n",
        "    def load(self):\n",
        "        if os.path.exists(self.gen_weights_path):\n",
        "            print('Loading %s generator...' % self.name)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                data = torch.load(self.gen_weights_path)\n",
        "            else:\n",
        "                data = torch.load(self.gen_weights_path, map_location=lambda storage, loc: storage)\n",
        "\n",
        "            self.generator.load_state_dict(data['generator'])\n",
        "            # self.iteration = data['iteration']\n",
        "            if self.config.LOADWITHEPOCH == 1:\n",
        "                self.epoch = data['epoch']\n",
        "\n",
        "        # load discriminator only when training\n",
        "        if self.config.MODE == 1 and os.path.exists(self.dis_weights_path):\n",
        "            print('Loading %s discriminator...' % self.name)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                data = torch.load(self.dis_weights_path)\n",
        "            else:\n",
        "                data = torch.load(self.dis_weights_path, map_location=lambda storage, loc: storage)\n",
        "\n",
        "            self.discriminator.load_state_dict(data['discriminator'])\n",
        "\n",
        "    def save(self, epoch):\n",
        "        print('\\nsaving %s...\\n' % self.name)\n",
        "        torch.save({\n",
        "            # 'iteration': self.iteration,\n",
        "            'generator': self.generator.state_dict(),\n",
        "            'epoch': epoch\n",
        "        }, os.path.join(os.path.dirname(self.gen_weights_path), self.name + '_%d_gen.pth' % (epoch)))\n",
        "\n",
        "        torch.save({\n",
        "            'discriminator': self.discriminator.state_dict()\n",
        "        }, os.path.join(os.path.dirname(self.dis_weights_path), self.name + '_%d_dis.pth' % (epoch)))\n",
        "\n",
        "\n",
        "class InpaintingModel(BaseModel):\n",
        "    def __init__(self, config):\n",
        "        super(InpaintingModel, self).__init__('InpaintingModel', config)\n",
        "\n",
        "        # generator input: [rgb(3)]\n",
        "        in_channel = 3\n",
        "        generator = PyramidNet(in_channel, config.BLOCKS)\n",
        "        # generator=UnetGeneratorSame()       Unet-lile generator\n",
        "        # summary(generator, (3, 256, 256), 6,device='cpu')\n",
        "        # print(generator)\n",
        "        # discriminator input: [rgb(3)]\n",
        "        discriminator = Discriminator(in_channels=3, use_sigmoid=config.GAN_LOSS != 'hinge')\n",
        "        params=sum([param.nelement() for param in generator.parameters()])\n",
        "        print(\"This Generative Model Total params: {}M /  {}K\".format (round((params>>10)/1024,2),params>>10))\n",
        "        params = sum([param.nelement() for param in discriminator.parameters()])\n",
        "        print(\"This Adversarial Model Total params: {}M /  {}K\".format(round((params>>10)/1024,2), params >> 10))\n",
        "        l1_loss = nn.L1Loss()\n",
        "        perceptual_loss = PerceptualLoss()\n",
        "        style_loss = StyleLoss()\n",
        "        adversarial_loss = AdversarialLoss(type=config.GAN_LOSS)\n",
        "        # gradient_loss = GradientLoss(independent=True, distance='L2')\n",
        "        gpus = config.GPU\n",
        "        gpus_list_0_start = list(range(len(gpus)))  # beause we set os.environ to change the visible GPUS in main,py\n",
        "        if len(config.GPU) > 1:\n",
        "            generator = nn.DataParallel(generator, gpus_list_0_start)\n",
        "            discriminator = nn.DataParallel(discriminator, gpus_list_0_start)\n",
        "            # generator =nn.DistributedDataParallel(generator, gpus_list_0_start)\n",
        "            # discriminator = nn.DistributedDataParallel(discriminator, gpus_list_0_start)\n",
        "        self.add_module('generator', generator)\n",
        "        self.add_module('discriminator', discriminator)\n",
        "        self.add_module('l1_loss', l1_loss)\n",
        "        self.add_module('perceptual_loss', perceptual_loss)\n",
        "        self.add_module('style_loss', style_loss)\n",
        "        self.add_module('adversarial_loss', adversarial_loss)\n",
        "        # self.add_module('gradient_loss', gradient_loss)\n",
        "        self.gen_optimizer = optim.Adam(\n",
        "            params=generator.parameters(),\n",
        "            lr=float(config.LR),\n",
        "            betas=(config.BETA1, config.BETA2)\n",
        "        )\n",
        "\n",
        "        self.dis_optimizer = optim.Adam(\n",
        "            params=discriminator.parameters(),\n",
        "            lr=float(config.LR) * float(config.D2G_LR),\n",
        "            betas=(config.BETA1, config.BETA2)\n",
        "        )\n",
        "\n",
        "    def process(self, images, masks):\n",
        "        self.iteration += 1\n",
        "\n",
        "        # zero optimizers\n",
        "        self.gen_optimizer.zero_grad()\n",
        "        self.dis_optimizer.zero_grad()\n",
        "\n",
        "        # process outputs\n",
        "        outputs = self(images, masks)\n",
        "        gen_loss = 0\n",
        "        dis_loss = 0\n",
        "\n",
        "        # discriminator loss\n",
        "        dis_input_real = images\n",
        "        # dis_input_real =torch.cat((images, masks), dim=1)\n",
        "        dis_input_fake = outputs.detach()\n",
        "        # dis_input_fake =torch.cat((outputs.detach(), masks), dim=1)\n",
        "\n",
        "        dis_input_real = DiffAugment(dis_input_real, policy=policy)\n",
        "        dis_input_fake = DiffAugment(dis_input_fake, policy=policy)\n",
        "\n",
        "        dis_real, dis_real_feat = self.discriminator(dis_input_real)  # in: [rgb(3)]\n",
        "        dis_fake, dis_fake_feat = self.discriminator(dis_input_fake)  # in: [rgb(3)]\n",
        "\n",
        "\n",
        "        dis_real_loss = self.adversarial_loss(dis_real, True, True)\n",
        "        dis_fake_loss = self.adversarial_loss(dis_fake, False, True)\n",
        "        dis_loss += (dis_real_loss + dis_fake_loss) / 2\n",
        "\n",
        "        # generator adversarial loss\n",
        "        gen_gan_loss = torch.FloatTensor([0])\n",
        "        if self.config.INPAINT_ADV_LOSS_WEIGHT > 0:\n",
        "            gen_input_fake = outputs\n",
        "            # gen_input_fake = torch.cat((outputs, masks), dim=1)\n",
        "            gen_input_fake = DiffAugment(gen_input_fake, policy=policy)\n",
        "            gen_fake, gen_fake_feat = self.discriminator(gen_input_fake)  # in: [rgb(3)]\n",
        "            gen_gan_loss = self.adversarial_loss(gen_fake, True, False) * self.config.INPAINT_ADV_LOSS_WEIGHT\n",
        "            gen_loss += gen_gan_loss\n",
        "\n",
        "        # generator feature matching loss\n",
        "        gen_fm_loss = torch.FloatTensor([0])\n",
        "        if self.config.FM_LOSS_WEIGHT > 0:\n",
        "            gen_fm_loss = 0\n",
        "            for i in range(len(dis_real_feat)):\n",
        "                gen_fm_loss += self.l1_loss(gen_fake_feat[i], dis_real_feat[i].detach())\n",
        "            gen_fm_loss = gen_fm_loss * self.config.FM_LOSS_WEIGHT\n",
        "            gen_loss += gen_fm_loss\n",
        "\n",
        "        # generator l1 loss\n",
        "        gen_l1_loss = torch.FloatTensor([0])\n",
        "        if self.config.L1_LOSS_WEIGHT > 0:\n",
        "            gen_l1_loss = self.l1_loss(outputs, images) * self.config.L1_LOSS_WEIGHT / torch.mean(1 - masks)\n",
        "            gen_loss += gen_l1_loss\n",
        "\n",
        "        # # generator perceptual loss\n",
        "        gen_content_loss = torch.FloatTensor([0])\n",
        "        if self.config.CONTENT_LOSS_WEIGHT > 0:\n",
        "            gen_content_loss = self.perceptual_loss(outputs, images)\n",
        "            gen_content_loss = gen_content_loss * self.config.CONTENT_LOSS_WEIGHT\n",
        "            gen_loss += gen_content_loss\n",
        "\n",
        "        # # generator style loss\n",
        "        gen_style_loss = torch.FloatTensor([0])\n",
        "        if self.config.STYLE_LOSS_WEIGHT > 0:\n",
        "            gen_style_loss = self.style_loss(outputs, images)\n",
        "            gen_style_loss = gen_style_loss * self.config.STYLE_LOSS_WEIGHT\n",
        "            gen_loss += gen_style_loss\n",
        "\n",
        "        # gradient loss\n",
        "        # gen_gradient_loss = torch.FloatTensor([0])\n",
        "        # if self.config.GRADIENT_LOSS_WEIGHT > 0:\n",
        "        #     gen_gradient_loss = self.gradient_loss(outputs, images)\n",
        "        #     gen_gradient_loss = gen_gradient_loss * self.config.GRADIENT_LOSS_WEIGHT\n",
        "        #     gen_loss += gen_gradient_loss\n",
        "        # create logs\n",
        "        logs = {\n",
        "            \"l_d2\": dis_loss.item(),\n",
        "            \"l_g2\": gen_gan_loss.item(),\n",
        "            \"l_l1\": gen_l1_loss.item(),\n",
        "            \"l_fm\": gen_fm_loss.item(),\n",
        "            \"l_per\": gen_content_loss.item(),\n",
        "            \"l_sty\": gen_style_loss.item(),\n",
        "            # 'l_grad': gen_gradient_loss.item()\n",
        "        }\n",
        "\n",
        "        if not self.training:\n",
        "            val_logs = {}\n",
        "            for key, value in logs.items():\n",
        "                key = \"val_\" + key\n",
        "                val_logs[key] = value\n",
        "            logs = val_logs\n",
        "        return outputs, gen_loss, dis_loss, logs\n",
        "\n",
        "    def forward(self, images, masks):\n",
        "        # images_masked = (images * (1 - masks).float()) + masks\n",
        "        images_masked = (images * (masks).float())\n",
        "        inputs = images_masked\n",
        "        outputs = self.generator(inputs)  # in: [rgb(3)]\n",
        "        return outputs\n",
        "\n",
        "    def backward(self, gen_loss=None, dis_loss=None):\n",
        "        dis_loss.backward()\n",
        "        self.dis_optimizer.step()\n",
        "\n",
        "        gen_loss.backward()\n",
        "        self.gen_optimizer.step()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrqfZY1J_8u-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/AdaptiveGAN\n",
        "!python3 train.py --checkpoints /content/model-checkpoints"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT782__eFZy4",
        "colab_type": "text"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJUo2M5-Fksl",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title config.yml (testing)\n",
        "%%writefile /content/checkpoints/config.yml\n",
        "MODE: 2             # 1: train, 2: test, 3: eval\n",
        "MASK: 3             # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)  6: one to one image mask\n",
        "SEED: 10            # random seed\n",
        "GPU: [0]            # list of gpu ids\n",
        "DEBUG: 0           # turns on debugging mode\n",
        "VERBOSE: 0          # turns on verbose mode in the output console\n",
        "\n",
        "TRAIN_FLIST: \"/content/train/train.tflist\"\n",
        "VAL_FLIST: \"/content/val/val.tflist\"\n",
        "TEST_FLIST: \"/content/val/val.tflist\"\n",
        "\n",
        "TRAIN_MASK_FLIST: \"/content/mask_train/mask_train.tflist\"\n",
        "VAL_MASK_FLIST: \"/content/mask_val/mask_val.tflist\"\n",
        "TEST_MASK_FLIST: \"/content/mask_val/mask_val.tflist\"\n",
        "\n",
        "BLOCKS: 4                     # set the res block in each stage\n",
        "LR: 1e-4                      # learning rate\n",
        "D2G_LR: 0.1                   # discriminator/generator learning rate ratio\n",
        "BETA1: 0.0                    # adam optimizer beta1\n",
        "BETA2: 0.9                    # adam optimizer beta2\n",
        "BATCH_SIZE: 1                 # input batch size for training #6\n",
        "INPUT_SIZE: 256               # input image size for training 0 for original size\n",
        "MAX_ITERS: 2e6                # maximum number of iterations to train the model\n",
        "MAX_STEPS: 5000               # maximum number of each epoch\n",
        "MAX_EPOCHES: 100              # maximum number of epoches\n",
        "LOADWITHEPOCH: 1              # if load epoch when loading model \n",
        "\n",
        "L1_LOSS_WEIGHT: 1             # l1 loss weight\n",
        "FM_LOSS_WEIGHT: 10            # feature-matching loss weight\n",
        "STYLE_LOSS_WEIGHT: 250        # style loss weight\n",
        "CONTENT_LOSS_WEIGHT: 0.1      # perceptual loss weight\n",
        "INPAINT_ADV_LOSS_WEIGHT: 0.1  # adversarial loss weight\n",
        "\n",
        "GAN_LOSS: nsgan               # nsgan | lsgan | hinge\n",
        "GAN_POOL_SIZE: 0              # fake images pool size\n",
        "\n",
        "SAVE_INTERVAL: 1000           # how many iterations to wait before saving model (0: never)\n",
        "SAMPLE_INTERVAL: 1000         # how many iterations to wait before sampling (0: never)\n",
        "SAMPLE_SIZE: 1               # number of images to sample #12\n",
        "EVAL_INTERVAL: 20             # How many INTERVAL sample while valuation  (0: never  36000 in places)\n",
        "LOG_INTERVAL: 10              # how many iterations to wait before logging training status (0: never)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETCbaKKGFu6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/AdaptiveGAN\n",
        "!python3 test.py \\\n",
        "  --checkpoints /content/model-checkpoints \\\n",
        "  --input /content/0.jpg \\\n",
        "  --mask /content/mask.png \\\n",
        "  --output /content/output.png"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}